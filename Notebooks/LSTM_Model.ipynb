{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Influence of technical indicators on the forecasting quality of machine learning models for the prediction of share prices</b></h2>\n",
    "<b>Author:</b> Benedikt Grimus</br>\n",
    "<b>E-Mail:</b> benedikt.grimus@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LSTM Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing the required packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulate data and mathematical operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# save and read files\n",
    "import os\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "# getting historical stock data\n",
    "import yfinance\n",
    "#work with times\n",
    "import datetime\n",
    "import time\n",
    "# create permutations\n",
    "import itertools\n",
    "# scale features and split data into training and testing set\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# LSTM model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "#error metric\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# kpss test\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Download historical stock data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_stock_data(tickers: list[str], start_date: datetime.datetime, end_date:datetime.datetime) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function retrieves historical stock data for a given list of tickers within a specified date range.\n",
    "    It uses the yfinance library to fetch the data and drops unnecessary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    tickers (list[str]): A list of stock ticker symbols for which historical data needs to be fetched.\n",
    "    start_date (datetime.datetime): The start date of the historical data period.\n",
    "    end_date (datetime.datetime): The end date of the historical data period.\n",
    "    \n",
    "    Returns:\n",
    "    list[pd.DataFrame]: A list of pandas DataFrames, each containing historical stock data for a single ticker. \n",
    "    A single data frame contains two columns, the open and the close price and uses the date as the index.\n",
    "    If an error occurs while fetching data for a ticker, it is removed from the list and a message is printed.\n",
    "    \"\"\"\n",
    "    hist_data_all_stocks = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            hist_data_all_stocks.append(yfinance.Ticker(ticker=ticker).history(start=start_date, end=end_date))\n",
    "            hist_data_all_stocks[-1] = hist_data_all_stocks[-1].drop([\"High\",\"Low\",\"Volume\",\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "        except:\n",
    "            tickers.remove(ticker)\n",
    "            print(f\"Error with ticker {ticker}! REMOVED it!\")\n",
    "    return hist_data_all_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test | is used for development purposes\n",
    "tickers = [\"AAPL\"]\n",
    "# S&P 500\n",
    "# tickers = [\"AAPL\",\"MSFT\",\"AMZN\",\"NVDA\",\"BRK-B\",\"GOOGL\",\"TSLA\",\"XOM\",\"UNH\",\"META\",\"JNJ\",\"JPM\",\"V\",\"PG\",\"HD\",\"MA\",\"CVX\",\"ABBV\",\"MRK\",\"LLY\",\"AVGO\",\"PEP\",\"KO\",\"PFE\",\"TMO\",\"COST\",\"BAC\",\"CSCO\",\"WMT\",\"MCD\"]\n",
    "# DAX\n",
    "# tickers = [\"SAP.DE\",\"SIE.DE\",\"ALV.DE\",\"DTE.DE\",\"AIR.DE\",\"BAYN.SG\",\"MBG.DE\",\"BAS.DE\",\"MUV2.MI\",\"IFX.DE\",\"DPW.DE\",\"DB1.DE\",\"VOW.DE\",\"BMW.DE\",\"RWE.DE\",\"MRK.DE\",\"DBK.DE\",\"ADS.DE\",\"EOAN.DE\",\"VNA.DE\",\"SHL.DE\",\"DTG.DE\",\"CBK.DE\",\"SY1.DE\",\"PAH3.DE\",\"MTX.DE\",\"HNR1.DE\",\"FRE.DE\",\"BEI.DE\",\"HEN3.DE\"]\n",
    "start_date = datetime.datetime(2020,1,1)\n",
    "end_date = datetime.datetime(2023,1,1)\n",
    "\n",
    "hist_data_all_stocks = get_historical_stock_data(tickers=tickers, start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculate technical indicators</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_technical_indicators(hist_data_all_stocks: list[pd.DataFrame], volatility_window: int = 20, momentum_window: int = 20, ma_window: int = 20) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function calculates technical indicators for a list of historical stock data DataFrames.\n",
    "    It calculates Volatility, Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), and Momentum.\n",
    "    \n",
    "    Parameters:\n",
    "    hist_data_all_stocks (list[pd.DataFrame]): A list of pandas DataFrames, each containing historical stock data for a single ticker.\n",
    "    volatility_window (int): The window size for calculating volatility. Default is 20.\n",
    "    momentum_window (int): The window size for calculating momentum. Default is 20.\n",
    "    ma_window (int): The window size for calculating moving average. Default is 20.\n",
    "    \n",
    "    Returns:\n",
    "    list[pd.DataFrame]: A list of pandas DataFrames, each containing the original historical stock data with added technical indicators.\n",
    "    \"\"\"\n",
    "    for i in range(len(hist_data_all_stocks)):\n",
    "        #Volatility\n",
    "        hist_data_all_stocks[i][f\"Vol_{volatility_window}\"] = hist_data_all_stocks[i]['Open'].rolling(volatility_window).std()\n",
    "        #RSI\n",
    "        delta = hist_data_all_stocks[i]['Open'].diff()\n",
    "        up = delta.clip(lower=0)\n",
    "        down = -1*delta.clip(upper=0)\n",
    "        ema_up = up.ewm(com=14, adjust=False).mean()\n",
    "        ema_down = down.ewm(com=14, adjust=False).mean()\n",
    "        rs = ema_up/ema_down\n",
    "        hist_data_all_stocks[i]['RSI'] = (100 - (100/(1 + rs)))\n",
    "        #MACD\n",
    "        hist_data_all_stocks[i]['MACD'] = hist_data_all_stocks[i]['Open'].ewm(span=12).mean() - hist_data_all_stocks[i]['Open'].ewm(span=26).mean()\n",
    "        #Momentum\n",
    "        hist_data_all_stocks[i][f'Mom_{momentum_window}'] = hist_data_all_stocks[i]['Open'] - hist_data_all_stocks[i]['Open'].shift(momentum_window)\n",
    "        #Moving Average\n",
    "        hist_data_all_stocks[i][f'MA_{ma_window}'] = hist_data_all_stocks[i]['Open'].rolling(ma_window).mean()\n",
    "        #Drop na values\n",
    "        hist_data_all_stocks[i] = hist_data_all_stocks[i].dropna()\n",
    "        #Rearrange the order of the columns so that the target is at the end\n",
    "        hist_data_all_stocks[i].insert(len(hist_data_all_stocks[i].columns) - 1, \"Close\", hist_data_all_stocks[i].pop('Close'))\n",
    "    return hist_data_all_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_all_stocks = calc_technical_indicators(hist_data_all_stocks=hist_data_all_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Establish stationarity using the first difference method</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of all data frames because it is needed to reverse the first difference method which is used to establish stationarity\n",
    "hist_data_all_stocks_non_stationary = []\n",
    "for i in range(len(hist_data_all_stocks)):\n",
    "    hist_data_all_stocks_non_stationary.append(hist_data_all_stocks[i].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stationary(hist_data_all_stocks: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function makes the time series data stationary by applying the first difference method.\n",
    "    The first difference method calculates the difference between consecutive observations.\n",
    "    This helps to remove trends and seasonality from the data, making it easier to analyze and model.\n",
    "\n",
    "    Parameters:\n",
    "    hist_data_all_stocks (list[pd.DataFrame]): A list of pandas DataFrames, each containing historical stock data for a single ticker.\n",
    "        The data should be indexed by date and contain at least one column representing the stock price.\n",
    "\n",
    "    Returns:\n",
    "    list[pd.DataFrame]: A list of pandas DataFrames, each containing the stationary historical stock data for a single ticker.\n",
    "        The first difference method has been applied to remove trends and seasonality.\n",
    "    \"\"\"\n",
    "    for i in range(len(hist_data_all_stocks)):\n",
    "        hist_data_all_stocks[i] = hist_data_all_stocks[i].diff().dropna()\n",
    "    return hist_data_all_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_all_stocks_stationary = make_stationary(hist_data_all_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Check for stationarity using the KPSS test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationary(data: pd.Series, significance: float = 0.05):\n",
    "    \"\"\"\n",
    "    This function tests the stationarity of a given time series data using the KPSS test.\n",
    "    The KPSS test is a statistical test for checking if a time series is stationary around a deterministic trend.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.Series): The time series data to be tested for stationarity. It should be indexed by date.\n",
    "    significance (float): The significance level for the KPSS test. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the time series is stationary (p-value >= significance), False otherwise.\n",
    "    \"\"\"\n",
    "    statistic, p_value, n_lags, critical_values = kpss(data)\n",
    "    for key, value in critical_values.items():\n",
    "        if p_value < significance:\n",
    "            return False\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through all companies and technical indicators\n",
    "for i in range(len(hist_data_all_stocks_stationary)):\n",
    "    for j in range(len(hist_data_all_stocks_stationary[i].columns)):\n",
    "        if test_stationary(hist_data_all_stocks_stationary[i][hist_data_all_stocks_stationary[i].columns[j]]) != True:\n",
    "            print(f\"{tickers[i]} {hist_data_all_stocks_stationary[i].columns[j]} not stationary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create all possible feature combinations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates all possible feature combinations and adds the Close column as the target column to the data frame\n",
    "feature_combinations = []\n",
    "n_features = hist_data_all_stocks_stationary[0].columns[0:len(hist_data_all_stocks_stationary[0].columns) - 1].tolist()\n",
    "for i in range(len(hist_data_all_stocks_stationary[0].columns) + 1):\n",
    "    for subset in itertools.combinations(n_features, i):\n",
    "        if(len(subset) != 0):\n",
    "            feature_combinations.append(list(subset))\n",
    "            feature_combinations[-1].append(\"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assing the lists with the data frames to a single list \n",
    "# A list containing different lists which contain data frames each with a different subset of features and the target variable\n",
    "hist_data_all_stocks_feature_combinations = []\n",
    "for i in range(len(hist_data_all_stocks)):\n",
    "    all_feature_combinations_single_stock = []\n",
    "    for j in range(len(feature_combinations)):\n",
    "        all_feature_combinations_single_stock.append(hist_data_all_stocks_stationary[i][feature_combinations[j]])\n",
    "    hist_data_all_stocks_feature_combinations.append(all_feature_combinations_single_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scale between 0 and 1 using MinMaScaler</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values(hist_data_all_stocks_feature_combinations: list[pd.DataFrame]) -> tuple[list[np.ndarray], list[np.ndarray], list[MinMaxScaler], list[MinMaxScaler]]:\n",
    "    \"\"\"\n",
    "    This function scales the features and target values of a list of data frames using MinMaxScaler.\n",
    "    The scalers are returned to be able to scale the predicted values back.\n",
    "\n",
    "    Parameters:\n",
    "    hist_data_all_stocks_feature_combinations (list[pd.DataFrame]): A list of data frames, each containing a different combination of features and the target variable.\n",
    "        The data frames should have columns representing the features and a 'Close' column representing the target variable.\n",
    "\n",
    "    Returns:\n",
    "    tuple[list[np.ndarray], list[np.ndarray], list[MinMaxScaler], list[MinMaxScaler]]: A tuple containing four lists:\n",
    "        - scaled_features_all_stocks: A list of lists, where each inner list contains the scaled features of the corresponding data frame in the input list.\n",
    "        - scaled_target_all_stocks: A list of lists, where each inner list contains the scaled target values of the corresponding data frame in the input list.\n",
    "        - feature_scaler_all_stocks: A list of MinMaxScaler objects, each corresponding to the scaler used to scale the features of the corresponding data frame.\n",
    "        - target_scaler_all_stocks: A list of MinMaxScaler objects, each corresponding to the scaler used to scale the target values of the corresponding data frame.\n",
    "    \"\"\"\n",
    "    #The scalers are returned to be able to scale the predicted values back\n",
    "    feature_scaler_all_stocks = []\n",
    "    scaled_features_all_stocks = []\n",
    "    target_scaler_all_stocks = []\n",
    "    scaled_target_all_stocks = []\n",
    "    for i in range(len(hist_data_all_stocks_feature_combinations)):\n",
    "        feature_scaler_single_stock = []\n",
    "        scaled_features_single_stock = []\n",
    "        target_scaler_single_stock = []\n",
    "        scaled_target_single_stock = []\n",
    "        for j in range(len(hist_data_all_stocks_feature_combinations[i])):\n",
    "            features = hist_data_all_stocks_feature_combinations[i][j].loc[:,~hist_data_all_stocks_feature_combinations[i][j].columns.isin(['Close'])]\n",
    "            feature_scaler = MinMaxScaler()\n",
    "            scaled_features_single_stock.append(feature_scaler.fit_transform(features))\n",
    "            feature_scaler_single_stock.append(feature_scaler)\n",
    "            \n",
    "            target = hist_data_all_stocks_feature_combinations[i][j].loc[:,hist_data_all_stocks_feature_combinations[i][j].columns.isin(['Close'])]\n",
    "            target_scaler = MinMaxScaler()\n",
    "            scaled_target_single_stock.append(target_scaler.fit_transform(target))\n",
    "            target_scaler_single_stock.append(target_scaler)\n",
    "        \n",
    "        scaled_features_all_stocks.append(scaled_features_single_stock)\n",
    "        feature_scaler_all_stocks.append(feature_scaler_single_stock)\n",
    "        scaled_target_all_stocks.append(scaled_target_single_stock)\n",
    "        target_scaler_all_stocks.append(target_scaler_single_stock)\n",
    "\n",
    "    return scaled_features_all_stocks, scaled_target_all_stocks, feature_scaler_all_stocks, target_scaler_all_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_all_stocks, scaled_target_all_stocks, feature_scaler_all_stocks, target_scaler_all_stocks = scale_values(hist_data_all_stocks_feature_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split into training and testing set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(scaled_features_all_stocks, scaled_target_all_stocks, train_size=0.8) -> list[list, list, list, list]:\n",
    "    \"\"\"\n",
    "    This function splits the scaled features and targets into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "    scaled_features_all_stocks (list): A list containing a list for each examined stock, which contains lists with the scaled features for all different feature combinations.\n",
    "    scaled_target_all_stocks (list): A list containing a list for each examined stock, which contains lists with the scaled targets for all different feature combinations.\n",
    "    train_size (float, optional): The proportion of the data to include in the training set. Default is 0.8.\n",
    "    \n",
    "    Returns:\n",
    "    train_test_all_stocks (list): A list containing a list for each stock which contains a list for each feature combination. Each inner list contains four lists: features train, features test, targets train, targets test.\n",
    "    \"\"\"\n",
    "    train_test_all_stocks = []\n",
    "    for i in range(len(scaled_features_all_stocks)):\n",
    "        train_test_single_stock = []\n",
    "        for j in range(len(scaled_features_all_stocks[i])):\n",
    "            x_train, x_test, y_train, y_test = train_test_split(scaled_features_all_stocks[i][j], scaled_target_all_stocks[i][j], train_size=train_size, shuffle=False)\n",
    "            train_test_single_stock.append([x_train, x_test, y_train, y_test])\n",
    "        train_test_all_stocks.append(train_test_single_stock)\n",
    "    return train_test_all_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_all_stocks = split_data(scaled_features_all_stocks, scaled_target_all_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bring the training and testing dataset into the right format (samples, LSTM_input_vector_size, features)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(x_values: list, y_values: list, LSTM_input_vector_size: int = 10):\n",
    "    \"\"\"\n",
    "    Format the dataset for LSTM input.\n",
    "\n",
    "    Parameters:\n",
    "    x_values (numpy.ndarray): A numpy array containing the timeseries features.\n",
    "    y_values (numpy.ndarray): A numpy array containing the corresponding target values.\n",
    "    LSTM_input_vector_size (int, optional): The size of the input vector for the LSTM model. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    dataX (numpy.ndarray): A numpy array containing the input vectors for the LSTM model.\n",
    "    dataY (numpy.ndarray): A numpy array containing the corresponding target values for the LSTM model.\n",
    "    \"\"\"\n",
    "    dataX, dataY = [], []\n",
    "\n",
    "    for i in range(LSTM_input_vector_size, len(x_values)):\n",
    "        #dataX.append(x_values[(i - LSTM_input_vector_size):i, :])\n",
    "        dataX.append(x_values[(i - LSTM_input_vector_size):i])\n",
    "        dataY.append(y_values[i])\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector_size: int = 10\n",
    "\n",
    "for i in range(len(train_test_all_stocks)):\n",
    "    for j in range(len(train_test_all_stocks[i])):\n",
    "        train_test_all_stocks[i][j][0], train_test_all_stocks[i][j][2] = format_dataset(train_test_all_stocks[i][j][0], train_test_all_stocks[i][j][2], input_vector_size)\n",
    "        train_test_all_stocks[i][j][1], train_test_all_stocks[i][j][3] = format_dataset(train_test_all_stocks[i][j][1], train_test_all_stocks[i][j][3], input_vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: X=(578, 10, 6) Y=(578, 1)\n",
      "Testing Set Shape: X=(137, 10, 6) Y=(137, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set Shape: X={train_test_all_stocks[i][j][0].shape} Y={train_test_all_stocks[i][j][2].shape}\")\n",
    "print(f\"Testing Set Shape: X={train_test_all_stocks[i][j][1].shape} Y={train_test_all_stocks[i][j][3].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function for creating a LSTM model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(LSTM_input_vector_size: int, n_features: int) -> Sequential:\n",
    "    \"\"\"\n",
    "    This function creates a LSTM model for predicting stock prices.\n",
    "\n",
    "    Parameters:\n",
    "    LSTM_input_vector_size (int): The size of the input vector for the LSTM model.\n",
    "    features (int): The number of features in the input data.\n",
    "\n",
    "    Returns:\n",
    "    model (Sequential): A compiled LSTM model for predicting stock prices.\n",
    "    \"\"\"\n",
    "    neurons = n_features * LSTM_input_vector_size\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, return_sequences=True, input_shape=(LSTM_input_vector_size, n_features)))\n",
    "    model.add(LSTM(neurons, return_sequences=True))\n",
    "    model.add(LSTM(neurons, return_sequences=False))\n",
    "    model.add(Dense(n_features))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function for saving and loading a trained model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: Sequential, ticker: str, id: int) -> None:\n",
    "    \"\"\"\n",
    "    This function saves a trained LSTM model to a specified file path.\n",
    "\n",
    "    Parameters:\n",
    "    model (tensorflow.keras.models.Sequential): The trained LSTM model to be saved.\n",
    "    ticker (str): The string representing the stock the model was trained on.\n",
    "    id (int): A number used to differentiate between the feature combination that was used to train the model.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    file_path = \"{}{}{}{}{}\".format(os.getcwd(), os.sep, \"Pretrained_LSTM_Models\", os.sep,f\"model_{ticker}_{id}.h5\")\n",
    "    model.save(file_path)\n",
    "    \n",
    "def load_pretrained_model(ticker: str, id: int):\n",
    "    \"\"\"\n",
    "    This function loads a pre-trained LSTM model from a specified file path.\n",
    "\n",
    "    Parameters:\n",
    "    ticker (str): The string representing the stock the model was trained on.\n",
    "    id (int): A number used to differentiate between the feature combination that was used to train the model.\n",
    "\n",
    "    Returns:\n",
    "    model (tensorflow.keras.models.Sequential): The loaded pre-trained LSTM model.\n",
    "    \"\"\"\n",
    "    file_path = \"{}{}{}{}{}\".format(os.getcwd(), os.sep, \"Pretrained_LSTM_Models\", os.sep,f\"model_{ticker}_{id}.h5\")\n",
    "    model = load_model(file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train the LSTM models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Model: 6 of 63\n",
      "Expected remaining time: 23.06min or 1384.0s Current Ø time per model: 24.3s\n",
      "Create Model: 12 of 63\n",
      "Expected remaining time: 20.89min or 1253.0s Current Ø time per model: 24.6s\n",
      "Create Model: 18 of 63\n",
      "Expected remaining time: 18.32min or 1099.0s Current Ø time per model: 24.4s\n",
      "Create Model: 24 of 63\n",
      "Expected remaining time: 16.33min or 980.0s Current Ø time per model: 25.1s\n",
      "Create Model: 30 of 63\n",
      "Expected remaining time: 14.13min or 848.0s Current Ø time per model: 25.7s\n",
      "Create Model: 36 of 63\n",
      "Expected remaining time: 11.66min or 700.0s Current Ø time per model: 25.9s\n",
      "Create Model: 42 of 63\n",
      "Expected remaining time: 9.16min or 550.0s Current Ø time per model: 26.2s\n",
      "Create Model: 48 of 63\n",
      "Expected remaining time: 6.64min or 398.0s Current Ø time per model: 26.6s\n",
      "Create Model: 54 of 63\n",
      "Expected remaining time: 4.04min or 242.0s Current Ø time per model: 26.9s\n",
      "Create Model: 60 of 63\n",
      "Expected remaining time: 1.37min or 82.0s Current Ø time per model: 27.4s\n"
     ]
    }
   ],
   "source": [
    "#Depending of the number of tickers training takes several hours\n",
    "time_of_training = []\n",
    "number_of_models = len(tickers) * len(feature_combinations)\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 8\n",
    "#Loop through each stock\n",
    "for i in range(len(train_test_all_stocks)):\n",
    "    #Loop through all feature combinations\n",
    "    for j in range(len(train_test_all_stocks[i])):\n",
    "        model_start_time = time.time()\n",
    "        current_model_number = i * len(train_test_all_stocks[i]) + j + 1\n",
    "        model = create_model(train_test_all_stocks[i][j][0].shape[1], train_test_all_stocks[i][j][0].shape[2])\n",
    "        model.fit(train_test_all_stocks[i][j][0], train_test_all_stocks[i][j][2], validation_data=(train_test_all_stocks[i][j][1], train_test_all_stocks[i][j][3]), epochs=epochs, batch_size=batch_size ,verbose=0)\n",
    "        save_model(model, tickers[i], j)\n",
    "        time_of_training.append(time.time() - model_start_time)\n",
    "        expected_remaining_time = np.round(np.mean(time_of_training) * (number_of_models - current_model_number) / 60, 2)\n",
    "        #Print the remaining time\n",
    "        if(number_of_models >= 10):\n",
    "            if(current_model_number % int(number_of_models * 0.1) == 0):\n",
    "                print(f\"Create Model: {current_model_number} of {number_of_models}\")\n",
    "                print(f\"Expected remaining time: {expected_remaining_time}min or {np.round(expected_remaining_time*60, 0)}s Current Ø time per model: {np.round(np.mean(time_of_training),1)}s\")\n",
    "        else:\n",
    "            print(f\"Create Model: {current_model_number} of {number_of_models}\")\n",
    "            print(f\"Expected remaining time: {expected_remaining_time}min or {np.round(expected_remaining_time*60, 0)}s Current Ø time per model: {np.round(np.mean(time_of_training),1)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function for calculating the mean absolute percentage error</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mape(actual: list, predicted: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Mean Absolute Percentage Error (MAPE) between two sets of values.\n",
    "\n",
    "    Parameters:\n",
    "    actual (numpy.ndarray or list): The actual values.\n",
    "    predicted (numpy.ndarray or list): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The Mean Absolute Percentage Error (MAPE) between the actual and predicted values.\n",
    "    \"\"\"\n",
    "    mape = np.mean(np.abs((np.array(actual) - np.array(predicted)) / np.array(actual))) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create predictions using the models and calculate MAPE and accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boolean to control wheter the predictions and the targets from the test set should be saved (True) to be able to plot the predictions against the target\n",
    "save_predictions_and_y_test = True\n",
    "\n",
    "mape = []\n",
    "pred_rescaled_inversed_difference_all_stocks = []\n",
    "y_test_rescaled_inversed_difference_all_stocks = []\n",
    "y_test_direction_accuracy = []\n",
    "#Loop through all stocks\n",
    "for i in range(len(train_test_all_stocks)):\n",
    "    pred_rescaled_inversed_difference_single_stock = []\n",
    "    y_test_rescaled_inversed_difference_single_stock = []\n",
    "    #Loop through all feature combinations\n",
    "    for j in range(len(train_test_all_stocks[i])):\n",
    "        #Rescale the target variables (Close)\n",
    "        y_test_rescaled = target_scaler_all_stocks[i][j].inverse_transform(train_test_all_stocks[i][j][3])\n",
    "        #Load the model and predict\n",
    "        model = load_pretrained_model(tickers[i], j)\n",
    "        pred = model.predict(train_test_all_stocks[i][j][1], verbose=0)\n",
    "        #Rescale the prediction\n",
    "        pred_rescaled = target_scaler_all_stocks[i][j].inverse_transform(pred)\n",
    "        pred_rescaled_inversed_difference_single_stock_single_model = []\n",
    "        y_test_rescaled_inversed_difference_single_stock_single_model = []\n",
    "        same_direction = 0\n",
    "        #Calculate the accuracy by looping through the predictions\n",
    "        for k in range(len(pred_rescaled)):\n",
    "            if np.sign(pred_rescaled[k]) == np.sign(y_test_rescaled[k]):\n",
    "                same_direction += 1\n",
    "                #Reverse the first difference method\n",
    "            pred_rescaled_inversed_difference_single_stock_single_model.append(hist_data_all_stocks_non_stationary[i]['Close'].iloc[len(hist_data_all_stocks_non_stationary[i]['Close']) - len(pred_rescaled) + k] + pred_rescaled[k])\n",
    "            y_test_rescaled_inversed_difference_single_stock_single_model.append(hist_data_all_stocks_non_stationary[i]['Close'].iloc[len(hist_data_all_stocks_non_stationary[i]['Close']) - len(pred_rescaled) + k] + y_test_rescaled[k])\n",
    "        y_test_direction_accuracy.append(same_direction / len(pred_rescaled))\n",
    "        pred_rescaled_inversed_difference_single_stock.append(pred_rescaled_inversed_difference_single_stock_single_model)\n",
    "        y_test_rescaled_inversed_difference_single_stock.append(y_test_rescaled_inversed_difference_single_stock)\n",
    "        #Calculate the MAPE\n",
    "        mape.append(calc_mape(y_test_rescaled_inversed_difference_single_stock_single_model, pred_rescaled_inversed_difference_single_stock_single_model))\n",
    "    if save_predictions_and_y_test:\n",
    "        pred_rescaled_inversed_difference_all_stocks.append(pred_rescaled_inversed_difference_single_stock)\n",
    "        y_test_rescaled_inversed_difference_all_stocks.append(y_test_rescaled_inversed_difference_single_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the x labels for plotting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create x labels is nothing else than just removing the \"Close\" column from the feature combinations\n",
    "x_labels = []\n",
    "for i in range(len(feature_combinations)):\n",
    "    string = \"\"\n",
    "    for j in range(len(feature_combinations[i])):\n",
    "        if(feature_combinations[i][j] != \"Close\"):\n",
    "            string += feature_combinations[i][j]\n",
    "            if j != len(feature_combinations[i]) - 2:\n",
    "                string += \" + \\n\"\n",
    "    x_labels.append(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create a data frame containg the accuracy results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open dir. acc.</th>\n",
       "      <th>Vol_20 dir. acc.</th>\n",
       "      <th>RSI dir. acc.</th>\n",
       "      <th>MACD dir. acc.</th>\n",
       "      <th>Mom_20 dir. acc.</th>\n",
       "      <th>MA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 dir. acc.</th>\n",
       "      <th>Open + \\nRSI dir. acc.</th>\n",
       "      <th>Open + \\nMACD dir. acc.</th>\n",
       "      <th>Open + \\nMom_20 dir. acc.</th>\n",
       "      <th>...</th>\n",
       "      <th>Vol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Vol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>RSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Vol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.49635</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.49635</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.489051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.474453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open dir. acc.  Vol_20 dir. acc.  RSI dir. acc.  MACD dir. acc.  \\\n",
       "AAPL        0.510949          0.474453       0.474453        0.481752   \n",
       "\n",
       "      Mom_20 dir. acc.  MA_20 dir. acc.  Open + \\nVol_20 dir. acc.  \\\n",
       "AAPL           0.49635         0.518248                    0.49635   \n",
       "\n",
       "      Open + \\nRSI dir. acc.  Open + \\nMACD dir. acc.  \\\n",
       "AAPL                0.481752                 0.474453   \n",
       "\n",
       "      Open + \\nMom_20 dir. acc.  ...  \\\n",
       "AAPL                   0.489051  ...   \n",
       "\n",
       "      Vol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                       0.474453   \n",
       "\n",
       "      Vol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                        0.518248   \n",
       "\n",
       "      RSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                     0.532847   \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 dir. acc.  \\\n",
       "AAPL                                           0.474453       \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.510949      \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.518248        \n",
       "\n",
       "      Open + \\nVol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.518248         \n",
       "\n",
       "      Open + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.525547      \n",
       "\n",
       "      Vol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.532847        \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \n",
       "AAPL                                           0.474453                \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_direction = pd.DataFrame(np.array(y_test_direction_accuracy).reshape(-1,len(x_labels)), columns=[x_labels + \" dir. acc.\" for x_labels in x_labels], index=tickers)\n",
    "results_df_direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create a data frame containg the MAPE results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Vol_20</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Mom_20</th>\n",
       "      <th>MA_20</th>\n",
       "      <th>Open + \\nVol_20</th>\n",
       "      <th>Open + \\nRSI</th>\n",
       "      <th>Open + \\nMACD</th>\n",
       "      <th>Open + \\nMom_20</th>\n",
       "      <th>...</th>\n",
       "      <th>Vol_20 + \\nRSI + \\nMom_20 + \\nMA_20</th>\n",
       "      <th>Vol_20 + \\nMACD + \\nMom_20 + \\nMA_20</th>\n",
       "      <th>RSI + \\nMACD + \\nMom_20 + \\nMA_20</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMA_20</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMom_20 + \\nMA_20</th>\n",
       "      <th>Open + \\nVol_20 + \\nMACD + \\nMom_20 + \\nMA_20</th>\n",
       "      <th>Open + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20</th>\n",
       "      <th>Vol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.703692</td>\n",
       "      <td>1.747248</td>\n",
       "      <td>1.754036</td>\n",
       "      <td>1.733122</td>\n",
       "      <td>1.697673</td>\n",
       "      <td>1.699659</td>\n",
       "      <td>1.70872</td>\n",
       "      <td>1.721277</td>\n",
       "      <td>1.711314</td>\n",
       "      <td>1.711275</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74082</td>\n",
       "      <td>1.696444</td>\n",
       "      <td>1.69306</td>\n",
       "      <td>1.791259</td>\n",
       "      <td>1.706525</td>\n",
       "      <td>1.751895</td>\n",
       "      <td>1.73694</td>\n",
       "      <td>1.692921</td>\n",
       "      <td>1.692591</td>\n",
       "      <td>2.008673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open    Vol_20       RSI      MACD    Mom_20     MA_20  \\\n",
       "AAPL  1.703692  1.747248  1.754036  1.733122  1.697673  1.699659   \n",
       "\n",
       "      Open + \\nVol_20  Open + \\nRSI  Open + \\nMACD  Open + \\nMom_20  ...  \\\n",
       "AAPL          1.70872      1.721277       1.711314         1.711275  ...   \n",
       "\n",
       "      Vol_20 + \\nRSI + \\nMom_20 + \\nMA_20  \\\n",
       "AAPL                              1.74082   \n",
       "\n",
       "      Vol_20 + \\nMACD + \\nMom_20 + \\nMA_20  RSI + \\nMACD + \\nMom_20 + \\nMA_20  \\\n",
       "AAPL                              1.696444                            1.69306   \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20  \\\n",
       "AAPL                                     1.791259   \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMA_20  \\\n",
       "AAPL                                    1.706525   \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMom_20 + \\nMA_20  \\\n",
       "AAPL                                      1.751895   \n",
       "\n",
       "      Open + \\nVol_20 + \\nMACD + \\nMom_20 + \\nMA_20  \\\n",
       "AAPL                                        1.73694   \n",
       "\n",
       "      Open + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20  \\\n",
       "AAPL                                    1.692921   \n",
       "\n",
       "      Vol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20  \\\n",
       "AAPL                                      1.692591   \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20  \n",
       "AAPL                                           2.008673      \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_mae = pd.DataFrame(np.array(mape).reshape(-1,len(x_labels)), columns=x_labels, index=tickers)\n",
    "results_df_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Merge the data frames and save them as an Excel file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Vol_20</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Mom_20</th>\n",
       "      <th>MA_20</th>\n",
       "      <th>Open + \\nVol_20</th>\n",
       "      <th>Open + \\nRSI</th>\n",
       "      <th>Open + \\nMACD</th>\n",
       "      <th>Open + \\nMom_20</th>\n",
       "      <th>...</th>\n",
       "      <th>Vol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Vol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>RSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Vol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "      <th>Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.703692</td>\n",
       "      <td>1.747248</td>\n",
       "      <td>1.754036</td>\n",
       "      <td>1.733122</td>\n",
       "      <td>1.697673</td>\n",
       "      <td>1.699659</td>\n",
       "      <td>1.70872</td>\n",
       "      <td>1.721277</td>\n",
       "      <td>1.711314</td>\n",
       "      <td>1.711275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.474453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open    Vol_20       RSI      MACD    Mom_20     MA_20  \\\n",
       "AAPL  1.703692  1.747248  1.754036  1.733122  1.697673  1.699659   \n",
       "\n",
       "      Open + \\nVol_20  Open + \\nRSI  Open + \\nMACD  Open + \\nMom_20  ...  \\\n",
       "AAPL          1.70872      1.721277       1.711314         1.711275  ...   \n",
       "\n",
       "      Vol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                       0.474453   \n",
       "\n",
       "      Vol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                        0.518248   \n",
       "\n",
       "      RSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                     0.532847   \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 dir. acc.  \\\n",
       "AAPL                                           0.474453       \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.510949      \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.518248        \n",
       "\n",
       "      Open + \\nVol_20 + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.518248         \n",
       "\n",
       "      Open + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.525547      \n",
       "\n",
       "      Vol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \\\n",
       "AAPL                                           0.532847        \n",
       "\n",
       "      Open + \\nVol_20 + \\nRSI + \\nMACD + \\nMom_20 + \\nMA_20 dir. acc.  \n",
       "AAPL                                           0.474453                \n",
       "\n",
       "[1 rows x 126 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file_name = 'LSTM_results_test'\n",
    "\n",
    "results_df_final = results_df_mae.join(results_df_direction)\n",
    "results_df_final.to_excel(excel_file_name + \".xlsx\", sheet_name=\"Final Results LSTM\")\n",
    "results_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculate the correlations between the MAE and the accuarcy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "for i in range(len(results_df_direction)):\n",
    "    correlations.append(np.corrcoef(results_df_direction.loc[tickers[i],:], results_df_mae.loc[tickers[i],:])[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create a data frame containing the correlations and save it as an Excel file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.509892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAPL\n",
       "0 -0.509892"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correlations = pd.DataFrame(np.array(correlations).reshape(-1,len(tickers)), columns=tickers)\n",
    "df_correlations.to_excel(excel_file_name + \"_Correlations.xlsx\", sheet_name=\"Correlations\")\n",
    "df_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot the MAPE against the direction accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x240c73f1400>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = itertools.cycle([(0,0,0.4),(0,0,0.8),(0.6,0,0),(0.8,0,0)])\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_facecolor([.75,.75,.75])\n",
    "ax.set_title(\"MAPE vs Accuracy\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"MAPE\")\n",
    "for i in range(len(results_df_direction)):\n",
    "    ax.scatter(results_df_mae.loc[results_df_mae.index[i]], results_df_direction.loc[results_df_direction.index[i]], color=next(colors), label=tickers[i])\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
